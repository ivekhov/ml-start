{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0339be6",
   "metadata": {},
   "source": [
    "Реализуем градиентный спуск для задачи поиска оптимальных коэффициентов в MSE регрессии!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979e44e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T12:58:41.642106Z",
     "start_time": "2023-04-13T12:58:40.558090Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f975d",
   "metadata": {},
   "source": [
    "Имеем 1000 объектов и 10 признаков у каждого (+таргет)!\n",
    "\n",
    "Обучим модель линейной регрессии:\n",
    "\n",
    "$$\n",
    "a(x) = \\beta_1 d_{1} + \\beta_2 d_{2} + \\beta_3 d_{3} + \\beta_4 d_{4} + \\beta_5 d_{5} + \\beta_6 d_{6} + \\beta_7 d_{7} + \\beta_8 d_{8} + \\beta_9 d_{9} + \\beta_{10} d_{10} + \\beta_0\n",
    "$$\n",
    "\n",
    "Которая минимизирует MSE:\n",
    "\n",
    "$$\n",
    "Q(a(X), Y) = \\sum_i^{1000} (a(x_i) - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bdb3c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T12:58:43.305319Z",
     "start_time": "2023-04-13T12:58:43.249314Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.113768</td>\n",
       "      <td>0.930064</td>\n",
       "      <td>0.330528</td>\n",
       "      <td>0.010987</td>\n",
       "      <td>0.265703</td>\n",
       "      <td>0.699462</td>\n",
       "      <td>0.058465</td>\n",
       "      <td>0.431643</td>\n",
       "      <td>0.650958</td>\n",
       "      <td>0.751820</td>\n",
       "      <td>30.147094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.380048</td>\n",
       "      <td>0.485946</td>\n",
       "      <td>0.870232</td>\n",
       "      <td>0.473401</td>\n",
       "      <td>0.454516</td>\n",
       "      <td>0.500864</td>\n",
       "      <td>0.471723</td>\n",
       "      <td>0.234329</td>\n",
       "      <td>0.072982</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>21.424402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768462</td>\n",
       "      <td>0.217706</td>\n",
       "      <td>0.727438</td>\n",
       "      <td>0.718377</td>\n",
       "      <td>0.452155</td>\n",
       "      <td>0.434638</td>\n",
       "      <td>0.043989</td>\n",
       "      <td>0.972489</td>\n",
       "      <td>0.450133</td>\n",
       "      <td>0.378157</td>\n",
       "      <td>31.422056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.606637</td>\n",
       "      <td>0.604335</td>\n",
       "      <td>0.540332</td>\n",
       "      <td>0.491236</td>\n",
       "      <td>0.325632</td>\n",
       "      <td>0.206348</td>\n",
       "      <td>0.825767</td>\n",
       "      <td>0.332475</td>\n",
       "      <td>0.955518</td>\n",
       "      <td>0.162811</td>\n",
       "      <td>31.308588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.119770</td>\n",
       "      <td>0.469718</td>\n",
       "      <td>0.632829</td>\n",
       "      <td>0.504207</td>\n",
       "      <td>0.238259</td>\n",
       "      <td>0.452457</td>\n",
       "      <td>0.775360</td>\n",
       "      <td>0.174262</td>\n",
       "      <td>0.117621</td>\n",
       "      <td>0.218883</td>\n",
       "      <td>23.322751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6   \n",
       "0   0.113768   0.930064   0.330528   0.010987   0.265703   0.699462  \\\n",
       "1   0.380048   0.485946   0.870232   0.473401   0.454516   0.500864   \n",
       "2   0.768462   0.217706   0.727438   0.718377   0.452155   0.434638   \n",
       "3   0.606637   0.604335   0.540332   0.491236   0.325632   0.206348   \n",
       "4   0.119770   0.469718   0.632829   0.504207   0.238259   0.452457   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10     target  \n",
       "0   0.058465   0.431643   0.650958    0.751820  30.147094  \n",
       "1   0.471723   0.234329   0.072982    0.008372  21.424402  \n",
       "2   0.043989   0.972489   0.450133    0.378157  31.422056  \n",
       "3   0.825767   0.332475   0.955518    0.162811  31.308588  \n",
       "4   0.775360   0.174262   0.117621    0.218883  23.322751  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data.csv')\n",
    "\n",
    "df = data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad05ac1",
   "metadata": {},
   "source": [
    "Обучим коэффициенты линейной регрессии с помощью библиотеки <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\"> **sklearn** </a>\n",
    "\n",
    "Отдельно выведем оценку свободного коэффициента  ($\\beta_0$ при $d_0 = 1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce59486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T12:58:46.369980Z",
     "start_time": "2023-04-13T12:58:45.646925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df.drop(['target'], axis=1)\n",
    "Y = df['target']\n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(X, Y)\n",
    "\n",
    "print(model.coef_)\n",
    "model.intercept_.round(2)\n",
    "\n",
    "### Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e82605",
   "metadata": {},
   "source": [
    "Теперь вам необходимо реализовать класс для оптимизации коэффициентов линейной регрессии МНК.\n",
    "Подразумевается, что на вход алгоритм будет принимать следующие параметры:\n",
    "\n",
    "- 2 pandas датафрейма **samples** и **targets**, содержащих матрицу объектов и ветор ответов соответственно\n",
    "- значение **learning rate**, который корректирует длину вектора-градиента (чтобы он не взорвался)\n",
    "- значение **threshold**'а для критерия останова (когда мы считаем, что мы сошлись к оптимуму)\n",
    "- параметр **copy**, который позволяет либо делать изменения in-place в датафрейме, подающимся в класс, если изменения матрицы объектов в принципе при обучении имеются. Или же копировать объект при инициализации класса и возвращать новый объект, если требуется.\n",
    "\n",
    "Он будет состоять из следующих важных компонент-методов:\n",
    "\n",
    "- **add_constant_feature**: добавляет колонку с названием *constant* из единичек к переданному датафрейму **samples**. Это позволяет оценить свободный коэффициент $\\beta_0$.\n",
    "\n",
    "- **calculate_mse_loss**: вычисляет при текущих весах **self.beta** значение среднеквадратической ошибки.\n",
    "\n",
    "- **calculate_gradient**: вычисляет при текущих весах вектор-градиент по функционалу.\n",
    "\n",
    "- **iteration**: производит итерацию градиентного спуска, то есть обновляет веса модели, в соответствии с установленным **learning_rate = $\\eta$**: $\\beta^{(n+1)} = \\beta^{(n)} - \\eta \\cdot \\nabla Q(\\beta^{(n)})$\n",
    "\n",
    "- **learn**: производит итерации обучения до того момента, пока не сработает критерий останова обучения. В этот раз критерием останова будет следующее событие: во время крайней итерации изменение в функционале качества модели составило значение меньшее, чем **self.threshold**. Иными словами, $|Q(\\beta^{(n)}) - Q(\\beta^{(n+1)})| < threshold$.\n",
    "\n",
    "P.S. установите в **__init__** аттрибут экземпляра с названием **iteration_loss_dict**, который будет устроен следующим образом: на каждой итерации мы будем добавлять в словарь пару ключ-значение, где ключем будет номер итерации $n$, а значением - среднеквадратическая ошибка в точке $\\beta^{(n)}$. Это пригодится нам в будущем для визуализации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43735e",
   "metadata": {},
   "source": [
    "### Hint: пример вычисления производной"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378d42fc",
   "metadata": {},
   "source": [
    "$$\n",
    "Q(a, X) = \\frac{1}{N}\\cdot\\sum_{i=1}^N (\\beta_1 \\cdot d_{i1} + ... + \\beta_n \\cdot d_{in} - y_i)^2\n",
    "$$\n",
    "\n",
    "Выше - минимизируемая функция. Она зависит от n переменных: $\\beta_1, ..., \\beta_n$. Вектор-градиент - матрица с одной строчкой, состоящей из производных 1го порядка по всем переменным.\n",
    "\n",
    "$$\n",
    "\\nabla Q(a, X) = (Q'_{\\beta_1} \\;\\;\\; Q'_{\\beta_2} \\;\\;\\; ... \\;\\;\\; Q'_{\\beta_{n-1}}  \\;\\;\\;  Q'_{\\beta_n})\n",
    "$$\n",
    "\n",
    "Пример вычисления производной по первой переменной:\n",
    "\n",
    "$$\n",
    "Q'_{\\beta_1} = \\frac{2}{N} \\cdot \\sum_{i=1}^N d_{i1} (\\beta_1 \\cdot d_{i1} + ... + \\beta_{n} \\cdot d_{in} - y_i)\n",
    "$$\n",
    "\n",
    "Скажем, для нашего датасета X, Y вычислим эту саму производную при начальных единичных коэффициентах $\\beta_{start} = (1 \\;\\;\\; 1 \\;\\;\\; ...)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ae2e0",
   "metadata": {},
   "source": [
    "Получим для каждого объекта в начале выражение из скобочек: \n",
    "$$\n",
    "\\beta_1 \\cdot d_{i1} + ... + \\beta_{n} \\cdot d_{in} - y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "866b95e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T12:09:49.038349Z",
     "start_time": "2023-04-13T12:09:49.030350Z"
    }
   },
   "outputs": [],
   "source": [
    "### Инициализируем точку для коэффициентов в виде вектора из единичек\n",
    "initial_betas = np.ones(X.shape[1])\n",
    "\n",
    "### Получим выражение выше для каждого объекта. \n",
    "### Для этого скалярно перемножим строчки из X на наши beta\n",
    "\n",
    "scalar_value = np.dot(X, initial_betas.reshape(-1, 1)).ravel()\n",
    "scalar_value = (scalar_value - Y).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ebd43b",
   "metadata": {},
   "source": [
    "Теперь полученное значение для каждого объекта умножим на соответствующее значение признака $d_1$:\n",
    "\n",
    "$$\n",
    "d_{i1} \\cdot (\\beta_1 \\cdot d_{i1} + ... + \\beta_{n} \\cdot d_{in} - y_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c1f8ca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T12:09:56.576490Z",
     "start_time": "2023-04-13T12:09:56.559487Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Возьмем столбик со значениями 1 признака\n",
    "\n",
    "d_i1 = X.values[:, 0]\n",
    "\n",
    "### Умножим каждый объект на соответствующее значение признака\n",
    "scalar_value = scalar_value * d_i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c3a822c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T12:09:58.966917Z",
     "start_time": "2023-04-13T12:09:58.951918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.62384887912409"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Наконец, умножим все на 2 и усреднимся, \n",
    "### чтобы получить значение производной по первому параметру\n",
    "\n",
    "2 * np.mean(scalar_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec92b8f",
   "metadata": {},
   "source": [
    "### Эта логика поможем Вам при реализации класса!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7f59b",
   "metadata": {},
   "source": [
    "learn(self)\n",
    "\n",
    "метод возвращает итоговую среднеквадратическую ошибку.\n",
    "метод итеративно вычисляет среднеквадратическую ошибку и вектор-градиент. номер итерации и MSE записываются в словарь *iteration_loss_dict*. критерий останова срабатывает тогда, когда абсолютное значение разницы двух последних MSE меньше *self.threshold*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06ea0c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:13:28.490032Z",
     "start_time": "2023-04-13T14:13:28.463028Z"
    }
   },
   "outputs": [],
   "source": [
    "class GradientDescentMse:\n",
    "    \"\"\"\n",
    "    Базовый класс для реализации градиентного спуска в задаче линейной МНК регрессии \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, samples: pd.DataFrame, targets: pd.DataFrame,\n",
    "                 learning_rate: float = 1e-3, threshold = 1e-6, copy: bool = True):\n",
    "        \"\"\"\n",
    "        self.samples - матрица признаков\n",
    "        self.targets - вектор таргетов\n",
    "        self.beta - вектор из изначальными весами модели == коэффициентами бета (состоит из единиц)\n",
    "        self.learning_rate - параметр *learning_rate* для корректировки нормы градиента\n",
    "        self.threshold - величина, меньше которой изменение в loss-функции означает остановку градиентного спуска\n",
    "        iteration_loss_dict - словарь, который будет хранить номер итерации и соответствующую MSE\n",
    "        copy: копирование матрицы признаков или создание изменения in-place\n",
    "        \"\"\"\n",
    "        ### Your code is here\n",
    "        if copy:\n",
    "            self.samples = samples.copy()\n",
    "        else:\n",
    "            self.samples = samples\n",
    "        \n",
    "        self.targets = targets\n",
    "        self.learning_rate = learning_rate\n",
    "        self.threshold = threshold\n",
    "        self.beta = np.ones(self.samples.shape[1])\n",
    "        self.iteration_loss_dict = {}\n",
    "        \n",
    "        \n",
    "    def add_constant_feature(self):\n",
    "        \"\"\"\n",
    "        Метод для создания константной фичи в матрице объектов samples\n",
    "        Метод создает колонку с константным признаком (interсept) в матрице признаков.\n",
    "        Hint: так как количество признаков увеличилось на одну, не забудьте дополнить вектор с изначальными весами модели!\n",
    "        \"\"\"\n",
    "        ### Your code is here\n",
    "        self.samples['constant'] = 1\n",
    "        self.beta = np.ones(self.samples.shape[1])\n",
    "        \n",
    "    def calculate_mse_loss(self) -> float:\n",
    "        \"\"\"\n",
    "        Метод для расчета среднеквадратической ошибки\n",
    "        \n",
    "        :return: среднеквадратическая ошибка при текущих весах модели : float\n",
    "        \"\"\"\n",
    "        ### Your code is here\n",
    "        predict = np.dot(self.samples, self.beta.reshape(-1, 1)).ravel()\n",
    "        mse = (((predict - self.targets)**2).mean())**0.5\n",
    "        return mse\n",
    "        \n",
    "\n",
    "    def calculate_gradient(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Метод для вычисления вектора-градиента\n",
    "        Метод возвращает вектор-градиент, содержащий производные по каждому признаку.\n",
    "        Сначала матрица признаков скалярно перемножается на вектор self.beta, и из каждой колонки\n",
    "        полученной матрицы вычитается вектор таргетов. Затем полученная матрица скалярно умножается на матрицу признаков.\n",
    "        Наконец, итоговая матрица умножается на 2 и усредняется по каждому признаку.\n",
    "        \n",
    "        :return: вектор-градиент, т.е. массив, содержащий соответствующее количество производных по каждой переменной : np.ndarray\n",
    "        \"\"\"\n",
    "        ### Your code is here\n",
    "        scalar_value = np.dot(self.samples, self.beta.reshape(-1, 1)).ravel()\n",
    "        scalar_value = (scalar_value - self.targets).values\n",
    "        grad = []\n",
    "        for i in range(self.samples.shape[1]):\n",
    "            d_i = self.samples.values[:, i]\n",
    "            scalar = scalar_value * d_i\n",
    "            der = 2 * np.mean(scalar)\n",
    "            grad.append(der)\n",
    "        return grad\n",
    "    \n",
    "    def iteration(self):\n",
    "        \"\"\"\n",
    "        Обновляем веса модели в соответствии с текущим вектором-градиентом\n",
    "        \"\"\"\n",
    "        ### Your code is here\n",
    "        beta_new = self.beta - np.dot(self.learning_rate, self.calculate_gradient())\n",
    "        self.beta = beta_new\n",
    "        \n",
    "    def learn(self,use_betas: bool = True):\n",
    "        \"\"\"\n",
    "        Итеративное обучение весов модели до срабатывания критерия останова\n",
    "        Запись mse и номера итерации в iteration_loss_dict\n",
    "        \n",
    "        Описание алгоритма работы для изменения бет:\n",
    "            Фиксируем текущие beta -> start_betas\n",
    "            Делаем шаг градиентного спуска\n",
    "            Записываем новые beta -> new_betas\n",
    "            Пока |L(new_beta) - L(start_beta)| >= threshold:\n",
    "                Повторяем первые 3 шага\n",
    "                \n",
    "        Описание алгоритма работы для изменения функции потерь:\n",
    "            Фиксируем текущие mse -> previous_mse\n",
    "            Делаем шаг градиентного спуска\n",
    "            Записываем новые mse -> next_mse\n",
    "            Пока |(previous_mse) - (next_mse)| >= threshold:\n",
    "                Повторяем первые 3 шага\n",
    "        \"\"\"\n",
    "        ### Your code is here\n",
    "        \n",
    "        start_betas = self.beta\n",
    "        self.iteration()\n",
    "        new_betas = self.beta\n",
    "        \n",
    "        \n",
    "        count = 0\n",
    "        while sum(abs(start_betas - new_betas) >= self.threshold):\n",
    "            start_betas = self.beta\n",
    "            self.iteration()\n",
    "            new_betas = self.beta\n",
    "            count += 1\n",
    "            previous_mse = self.calculate_mse_loss()\n",
    "            self.iteration()\n",
    "            next_mse = self.calculate_mse_loss()\n",
    "            self.iteration_loss_dict[count] = next_mse\n",
    "        \n",
    "            \n",
    "        count = 0\n",
    "        previous_mse = self.calculate_mse_loss()\n",
    "        self.iteration()\n",
    "        next_mse = self.calculate_mse_loss()\n",
    "        self.iteration_loss_dict[count] = next_mse\n",
    "        \n",
    "        while abs(previous_mse - next_mse) >= self.threshold:\n",
    "            count += 1\n",
    "            previous_mse = self.calculate_mse_loss()\n",
    "            self.iteration()\n",
    "            next_mse = self.calculate_mse_loss()\n",
    "            self.iteration_loss_dict[count] = next_mse\n",
    "        \n",
    "       \n",
    "            \n",
    "        return self.iteration_loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6827af",
   "metadata": {},
   "source": [
    "Обучим коэффициенты линейной модели с помощью реализованного нами градиентного спуска, не забыв добавить свободную переменную. Получились ли такие же коэффициенты, как и при использовании **LinearRegression** из **sklearn**? Если нет, то почему они отличаются, на Ваш взгляд, и сильно ли?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a192831e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:16:34.258278Z",
     "start_time": "2023-04-13T14:13:33.121591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 4s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GD = GradientDescentMse(samples=X, targets=Y)\n",
    "GD.add_constant_feature()\n",
    "Q = GD.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66701b5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:16:42.226134Z",
     "start_time": "2023-04-13T14:16:42.209133Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса модели при переменных d0, d1, ..., d10 равны соответственно: \n",
      "\n",
      "[0.99554916 1.99629212 2.99542312 3.99533575 4.99611361 5.99600299\n",
      " 6.99609408 7.99650311 8.99544873 9.9948624  4.39465089]\n"
     ]
    }
   ],
   "source": [
    "print('Веса модели при переменных d0, d1, ..., d10 равны соответственно: \\n\\n' + str(GD.beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.99554916 1.99629212 2.99542312 3.99533575 4.99611361 5.99600299\n",
    " 6.99609408 7.99650311 8.99544873 9.9948624  4.39465089]\n",
    "[0.88733305 1.90100713 2.88063607 3.87662612 4.89623507 5.89126182\n",
    " 6.89254811 7.90311947 8.87580109 9.86109585 4.94854733]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b4fa93",
   "metadata": {},
   "source": [
    "Попробуйте теперь изменить значения **learning_rate** и/или **threshold**. Например, установите длину шага $\\eta = 1$. Что произошло и почему такое возможно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df5ad318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:16:49.448657Z",
     "start_time": "2023-04-13T14:16:49.396651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 25.58558183113494,\n",
       " 2: 25.230421554907778,\n",
       " 3: 24.88030367849701,\n",
       " 4: 24.535158116271145,\n",
       " 5: 24.194915775359526,\n",
       " 6: 23.859508541781196,\n",
       " 7: 23.528869266767583,\n",
       " 8: 23.202931753276285,\n",
       " 9: 22.881630742693087,\n",
       " 10: 22.564901901719526,\n",
       " 11: 22.252681809443335,\n",
       " 12: 21.944907944589023,\n",
       " 13: 21.641518672946045,\n",
       " 14: 21.342453234971902,\n",
       " 15: 21.0476517335676,\n",
       " 16: 20.757055122023026,\n",
       " 17: 20.470605192129604,\n",
       " 18: 20.188244562457847,\n",
       " 19: 19.909916666797365,\n",
       " 20: 19.635565742756846,\n",
       " 21: 19.365136820521723,\n",
       " 22: 19.098575711767058,\n",
       " 23: 18.835828998723425,\n",
       " 24: 18.57684402339343,\n",
       " 25: 18.321568876916608,\n",
       " 26: 18.069952389080427,\n",
       " 27: 17.82194411797525,\n",
       " 28: 17.577494339790945,\n",
       " 29: 17.336554038753103,\n",
       " 30: 17.09907489719662,\n",
       " 31: 16.86500928577454,\n",
       " 32: 16.63431025380011,\n",
       " 33: 16.40693151971991,\n",
       " 34: 16.18282746171605,\n",
       " 35: 15.961953108435381,\n",
       " 36: 15.744264129843696,\n",
       " 37: 15.529716828203012,\n",
       " 38: 15.318268129169867,\n",
       " 39: 15.109875573012753,\n",
       " 40: 14.904497305946743,\n",
       " 41: 14.702092071583424,\n",
       " 42: 14.502619202494223,\n",
       " 43: 14.306038611885299,\n",
       " 44: 14.11231078538214,\n",
       " 45: 13.921396772922032,\n",
       " 46: 13.733258180752614,\n",
       " 47: 13.547857163534754,\n",
       " 48: 13.3651564165479,\n",
       " 49: 13.185119167996266,\n",
       " 50: 13.007709171414033,\n",
       " 51: 12.83289069816792,\n",
       " 52: 12.66062853005538,\n",
       " 53: 12.490887951996799,\n",
       " 54: 12.323634744819985,\n",
       " 55: 12.158835178135394,\n",
       " 56: 11.99645600330037,\n",
       " 57: 11.836464446470892,\n",
       " 58: 11.678828201739206,\n",
       " 59: 11.52351542435578,\n",
       " 60: 11.370494724034053,\n",
       " 61: 11.21973515833647,\n",
       " 62: 11.071206226140257,\n",
       " 63: 10.924877861181509,\n",
       " 64: 10.780720425676092,\n",
       " 65: 10.638704704015952,\n",
       " 66: 10.498801896539378,\n",
       " 67: 10.360983613373866,\n",
       " 68: 10.225221868350182,\n",
       " 69: 10.091489072986288,\n",
       " 70: 9.959758030539824,\n",
       " 71: 9.83000193012782,\n",
       " 72: 9.702194340912381,\n",
       " 73: 9.576309206351125,\n",
       " 74: 9.452320838511106,\n",
       " 75: 9.330203912445084,\n",
       " 76: 9.209933460628967,\n",
       " 77: 9.091484867459293,\n",
       " 78: 8.974833863809673,\n",
       " 79: 8.859956521645119,\n",
       " 80: 8.746829248693254,\n",
       " 81: 8.6354287831714,\n",
       " 82: 8.525732188568584,\n",
       " 83: 8.417716848481582,\n",
       " 84: 8.31136046150411,\n",
       " 85: 8.206641036168307,\n",
       " 86: 8.103536885937784,\n",
       " 87: 8.002026624251428,\n",
       " 88: 7.902089159617324,\n",
       " 89: 7.803703690756108,\n",
       " 90: 7.706849701793164,\n",
       " 91: 7.611506957499128,\n",
       " 92: 7.517655498578184,\n",
       " 93: 7.4252756370037245,\n",
       " 94: 7.334347951400982,\n",
       " 95: 7.244853282476298,\n",
       " 96: 7.156772728492764,\n",
       " 97: 7.070087640792027,\n",
       " 98: 6.984779619362077,\n",
       " 99: 6.9008305084509685,\n",
       " 100: 6.818222392226408,\n",
       " 101: 6.736937590481266,\n",
       " 102: 6.656958654385086,\n",
       " 103: 6.578268362281793,\n",
       " 104: 6.500849715533793,\n",
       " 105: 6.42468593441276,\n",
       " 106: 6.349760454037488,\n",
       " 107: 6.276056920359216,\n",
       " 108: 6.2035591861949,\n",
       " 109: 6.132251307309023,\n",
       " 110: 6.062117538544502,\n",
       " 111: 5.993142330003419,\n",
       " 112: 5.925310323278269,\n",
       " 113: 5.858606347734554,\n",
       " 114: 5.793015416845528,\n",
       " 115: 5.728522724580062,\n",
       " 116: 5.6651136418444885,\n",
       " 117: 5.602773712979547,\n",
       " 118: 5.541488652313353,\n",
       " 119: 5.481244340771573,\n",
       " 120: 5.4220268225458685,\n",
       " 121: 5.363822301821796,\n",
       " 122: 5.306617139567332,\n",
       " 123: 5.250397850383216,\n",
       " 124: 5.195151099416357,\n",
       " 125: 5.140863699337507,\n",
       " 126: 5.087522607384442,\n",
       " 127: 5.035114922471888,\n",
       " 128: 4.983627882369413,\n",
       " 129: 4.9330488609484675,\n",
       " 130: 4.883365365499804,\n",
       " 131: 4.834565034122356,\n",
       " 132: 4.786635633184769,\n",
       " 133: 4.739565054860589,\n",
       " 134: 4.6933413147381415,\n",
       " 135: 4.647952549506076,\n",
       " 136: 4.603387014715411,\n",
       " 137: 4.55963308261892,\n",
       " 138: 4.516679240088593,\n",
       " 139: 4.474514086611746,\n",
       " 140: 4.433126332366367,\n",
       " 141: 4.392504796376103,\n",
       " 142: 4.352638404745174,\n",
       " 143: 4.313516188973461,\n",
       " 144: 4.275127284351767,\n",
       " 145: 4.2374609284372635,\n",
       " 146: 4.200506459608856,\n",
       " 147: 4.164253315702185,\n",
       " 148: 4.128691032723744,\n",
       " 149: 4.093809243643518,\n",
       " 150: 4.059597677265342,\n",
       " 151: 4.02604615717407,\n",
       " 152: 3.9931446007584848,\n",
       " 153: 3.9608830183086896,\n",
       " 154: 3.929251512186641,\n",
       " 155: 3.8982402760682677,\n",
       " 156: 3.8678395942555204,\n",
       " 157: 3.838039841056504,\n",
       " 158: 3.808831480231771,\n",
       " 159: 3.7802050645046434,\n",
       " 160: 3.752151235133369,\n",
       " 161: 3.724660721542729,\n",
       " 162: 3.69772434101266,\n",
       " 163: 3.6713329984212875,\n",
       " 164: 3.645477686039701,\n",
       " 165: 3.6201494833756973,\n",
       " 166: 3.5953395570636193,\n",
       " 167: 3.5710391607973846,\n",
       " 168: 3.547239635303672,\n",
       " 169: 3.523932408352228,\n",
       " 170: 3.501108994800209,\n",
       " 171: 3.4787609966674022,\n",
       " 172: 3.456880103239196,\n",
       " 173: 3.435458091194128,\n",
       " 174: 3.4144868247528417,\n",
       " 175: 3.393958255845324,\n",
       " 176: 3.3738644242932576,\n",
       " 177: 3.354197458004429,\n",
       " 178: 3.33494957317612,\n",
       " 179: 3.3161130745044742,\n",
       " 180: 3.2976803553969245,\n",
       " 181: 3.2796438981848017,\n",
       " 182: 3.261996274333341,\n",
       " 183: 3.2447301446463874,\n",
       " 184: 3.2278382594632276,\n",
       " 185: 3.211313458845007,\n",
       " 186: 3.195148672748404,\n",
       " 187: 3.1793369211842397,\n",
       " 188: 3.1638713143589188,\n",
       " 189: 3.14874505279666,\n",
       " 190: 3.1339514274406195,\n",
       " 191: 3.119483819731171,\n",
       " 192: 3.1053357016596905,\n",
       " 193: 3.0915006357963732,\n",
       " 194: 3.077972275290738,\n",
       " 195: 3.0647443638435803,\n",
       " 196: 3.0518107356493256,\n",
       " 197: 3.0391653153078337,\n",
       " 198: 3.026802117704837,\n",
       " 199: 3.01471524786037,\n",
       " 200: 3.002898900744614,\n",
       " 201: 2.9913473610607824,\n",
       " 202: 2.980055002994723,\n",
       " 203: 2.9690162899310906,\n",
       " 204: 2.9582257741360314,\n",
       " 205: 2.9476780964064377,\n",
       " 206: 2.937367985685937,\n",
       " 207: 2.9272902586478926,\n",
       " 208: 2.917439819245763,\n",
       " 209: 2.9078116582312967,\n",
       " 210: 2.8984008526410827,\n",
       " 211: 2.889202565252096,\n",
       " 212: 2.8802120440069205,\n",
       " 213: 2.8714246214094166,\n",
       " 214: 2.862835713891661,\n",
       " 215: 2.8544408211530414,\n",
       " 216: 2.846235525472446,\n",
       " 217: 2.838215490994516,\n",
       " 218: 2.830376462990992,\n",
       " 219: 2.822714267098217,\n",
       " 220: 2.8152248085318616,\n",
       " 221: 2.807904071280009,\n",
       " 222: 2.800748117275708,\n",
       " 223: 2.7937530855501547,\n",
       " 224: 2.786915191367665,\n",
       " 225: 2.7802307253435834,\n",
       " 226: 2.773696052546323,\n",
       " 227: 2.767307611584682,\n",
       " 228: 2.76106191368161,\n",
       " 229: 2.7549555417355838,\n",
       " 230: 2.748985149370722,\n",
       " 231: 2.7431474599767878,\n",
       " 232: 2.7374392657401807,\n",
       " 233: 2.7318574266670166,\n",
       " 234: 2.7263988695993797,\n",
       " 235: 2.721060587225775,\n",
       " 236: 2.7158396370868476,\n",
       " 237: 2.7107331405773185,\n",
       " 238: 2.7057382819451603,\n",
       " 239: 2.7008523072889186,\n",
       " 240: 2.696072523554111,\n",
       " 241: 2.6913962975295918,\n",
       " 242: 2.6868210548447062,\n",
       " 243: 2.6823442789680927,\n",
       " 244: 2.677963510208885,\n",
       " 245: 2.6736763447210845,\n",
       " 246: 2.669480433511823,\n",
       " 247: 2.665373481454196,\n",
       " 248: 2.6613532463053287,\n",
       " 249: 2.6574175377302893,\n",
       " 250: 2.6535642163324438,\n",
       " 251: 2.6497911926908024,\n",
       " 252: 2.6460964264048923,\n",
       " 253: 2.6424779251476362,\n",
       " 254: 2.638933743726714,\n",
       " 255: 2.6354619831548294,\n",
       " 256: 2.6320607897292825,\n",
       " 257: 2.62872835412124,\n",
       " 258: 2.6254629104750205,\n",
       " 259: 2.6222627355177375,\n",
       " 260: 2.6191261476795864,\n",
       " 261: 2.6160515062250305,\n",
       " 262: 2.6130372103951416,\n",
       " 263: 2.610081698561303,\n",
       " 264: 2.607183447390477,\n",
       " 265: 2.604340971022202,\n",
       " 266: 2.601552820257469,\n",
       " 267: 2.598817581759624,\n",
       " 268: 2.596133877267375,\n",
       " 269: 2.593500362820032,\n",
       " 270: 2.5909157279950197,\n",
       " 271: 2.5883786951577497,\n",
       " 272: 2.585888018723867,\n",
       " 273: 2.5834424844339097,\n",
       " 274: 2.581040908640387,\n",
       " 275: 2.578682137607278,\n",
       " 276: 2.5763650468219224,\n",
       " 277: 2.5740885403192824,\n",
       " 278: 2.5718515500185313,\n",
       " 279: 2.569653035071923,\n",
       " 280: 2.5674919812258636,\n",
       " 281: 2.565367400194134,\n",
       " 282: 2.5632783290431673,\n",
       " 283: 2.5612238295892933,\n",
       " 284: 2.559202987807859,\n",
       " 285: 2.557214913254119,\n",
       " 286: 2.555258738495773,\n",
       " 287: 2.55333361855705,\n",
       " 288: 2.5514387303742097,\n",
       " 289: 2.549573272262318,\n",
       " 290: 2.5477364633931945,\n",
       " 291: 2.5459275432843627,\n",
       " 292: 2.5441457712988824,\n",
       " 293: 2.542390426155914,\n",
       " 294: 2.5406608054518585,\n",
       " 295: 2.5389562251919457,\n",
       " 296: 2.5372760193320856,\n",
       " 297: 2.5356195393308596,\n",
       " 298: 2.5339861537114765,\n",
       " 299: 2.5323752476335355,\n",
       " 300: 2.5307862224744526,\n",
       " 301: 2.5292184954203742,\n",
       " 302: 2.5276714990664244,\n",
       " 303: 2.5261446810261265,\n",
       " 304: 2.5246375035498354,\n",
       " 305: 2.5231494431520236,\n",
       " 306: 2.5216799902472533,\n",
       " 307: 2.520228648794683,\n",
       " 308: 2.518794935950943,\n",
       " 309: 2.5173783817312256,\n",
       " 310: 2.5159785286784246,\n",
       " 311: 2.5145949315401785,\n",
       " 312: 2.51322715695365,\n",
       " 313: 2.5118747831378974,\n",
       " 314: 2.5105373995936757,\n",
       " 315: 2.509214606810526,\n",
       " 316: 2.5079060159809887,\n",
       " 317: 2.506611248721811,\n",
       " 318: 2.5053299368019837,\n",
       " 319: 2.504061721877474,\n",
       " 320: 2.502806255232505,\n",
       " 321: 2.5015631975272474,\n",
       " 322: 2.5003322185517733,\n",
       " 323: 2.499112996986147,\n",
       " 324: 2.4979052201665084,\n",
       " 325: 2.4967085838570187,\n",
       " 326: 2.495522792027539,\n",
       " 327: 2.4943475566369098,\n",
       " 328: 2.4931825974217037,\n",
       " 329: 2.4920276416903313,\n",
       " 330: 2.4908824241223724,\n",
       " 331: 2.4897466865730116,\n",
       " 332: 2.488620177882464,\n",
       " 333: 2.4875026536902745,\n",
       " 334: 2.4863938762543647,\n",
       " 335: 2.4852936142747404,\n",
       " 336: 2.484201642721713,\n",
       " 337: 2.483117742668567,\n",
       " 338: 2.4820417011285385,\n",
       " 339: 2.4809733108960117,\n",
       " 340: 2.4799123703918293,\n",
       " 341: 2.478858683512625,\n",
       " 342: 2.4778120594840685,\n",
       " 343: 2.476772312717931,\n",
       " 344: 2.4757392626728882,\n",
       " 345: 2.474712733718951,\n",
       " 346: 2.47369255500545,\n",
       " 347: 2.4726785603324752,\n",
       " 348: 2.4716705880256957,\n",
       " 349: 2.470668480814461,\n",
       " 350: 2.469672085713116,\n",
       " 351: 2.468681253905443,\n",
       " 352: 2.4676958406321483,\n",
       " 353: 2.4667157050813246,\n",
       " 354: 2.465740710281809,\n",
       " 355: 2.4647707229993667,\n",
       " 356: 2.4638056136356195,\n",
       " 357: 2.462845256129666,\n",
       " 358: 2.461889527862308,\n",
       " 359: 2.4609383095628257,\n",
       " 360: 2.4599914852182367,\n",
       " 361: 2.4590489419849693,\n",
       " 362: 2.4581105701028925,\n",
       " 363: 2.457176262811642,\n",
       " 364: 2.456245916269179,\n",
       " 365: 2.4553194294725316,\n",
       " 366: 2.4543967041806534,\n",
       " 367: 2.4534776448393463,\n",
       " 368: 2.452562158508204,\n",
       " 369: 2.4516501547895064,\n",
       " 370: 2.4507415457590307,\n",
       " 371: 2.4498362458987137,\n",
       " 372: 2.4489341720311315,\n",
       " 373: 2.4480352432557386,\n",
       " 374: 2.4471393808868225,\n",
       " 375: 2.4462465083931346,\n",
       " 376: 2.445356551339142,\n",
       " 377: 2.444469437327871,\n",
       " 378: 2.4435850959452856,\n",
       " 379: 2.442703458706177,\n",
       " 380: 2.4418244590015066,\n",
       " 381: 2.4409480320471784,\n",
       " 382: 2.440074114834195,\n",
       " 383: 2.439202646080165,\n",
       " 384: 2.438333566182116,\n",
       " 385: 2.437466817170599,\n",
       " 386: 2.4366023426650227,\n",
       " 387: 2.435740087830211,\n",
       " 388: 2.4348799993341306,\n",
       " 389: 2.43402202530677,\n",
       " 390: 2.4331661153001334,\n",
       " 391: 2.4323122202493255,\n",
       " 392: 2.431460292434686,\n",
       " 393: 2.430610285444963,\n",
       " 394: 2.429762154141479,\n",
       " 395: 2.4289158546232765,\n",
       " 396: 2.4280713441932167,\n",
       " 397: 2.4272285813249894,\n",
       " 398: 2.426387525631032,\n",
       " 399: 2.4255481378313197,\n",
       " 400: 2.4247103797230016,\n",
       " 401: 2.4238742141508727,\n",
       " 402: 2.423039604978644,\n",
       " 403: 2.422206517061,\n",
       " 404: 2.4213749162164198,\n",
       " 405: 2.420544769200734,\n",
       " 406: 2.419716043681411,\n",
       " 407: 2.4188887082125423,\n",
       " 408: 2.4180627322105077,\n",
       " 409: 2.4172380859303133,\n",
       " 410: 2.4164147404425678,\n",
       " 411: 2.415592667611093,\n",
       " 412: 2.414771840071147,\n",
       " 413: 2.41395223120824,\n",
       " 414: 2.4131338151375314,\n",
       " 415: 2.41231656668379,\n",
       " 416: 2.4115004613619013,\n",
       " 417: 2.410685475357916,\n",
       " 418: 2.4098715855106025,\n",
       " 419: 2.4090587692935204,\n",
       " 420: 2.4082470047975733,\n",
       " 421: 2.4074362707140478,\n",
       " 422: 2.4066265463181105,\n",
       " 423: 2.4058178114527617,\n",
       " 424: 2.4050100465132274,\n",
       " 425: 2.4042032324317772,\n",
       " 426: 2.403397350662964,\n",
       " 427: 2.402592383169261,\n",
       " 428: 2.401788312407098,\n",
       " 429: 2.4009851213132793,\n",
       " 430: 2.400182793291774,\n",
       " 431: 2.3993813122008665,\n",
       " 432: 2.3985806623406645,\n",
       " 433: 2.3977808284409456,\n",
       " 434: 2.396981795649339,\n",
       " 435: 2.3961835495198307,\n",
       " 436: 2.3953860760015857,\n",
       " 437: 2.3945893614280784,\n",
       " 438: 2.3937933925065153,\n",
       " 439: 2.3929981563075544,\n",
       " 440: 2.392203640255307,\n",
       " 441: 2.391409832117608,\n",
       " 442: 2.39061671999656,\n",
       " 443: 2.389824292319335,\n",
       " 444: 2.3890325378292268,\n",
       " 445: 2.388241445576952,\n",
       " 446: 2.387451004912188,\n",
       " 447: 2.386661205475347,\n",
       " 448: 2.3858720371895714,\n",
       " 449: 2.385083490252951,\n",
       " 450: 2.3842955551309575,\n",
       " 451: 2.38350822254908,\n",
       " 452: 2.382721483485673,\n",
       " 453: 2.3819353291649885,\n",
       " 454: 2.3811497510504105,\n",
       " 455: 2.380364740837871,\n",
       " 456: 2.3795802904494465,\n",
       " 457: 2.3787963920271316,\n",
       " 458: 2.378013037926785,\n",
       " 459: 2.37723022071224,\n",
       " 460: 2.3764479331495774,\n",
       " 461: 2.3756661682015583,\n",
       " 462: 2.3748849190222066,\n",
       " 463: 2.374104178951542,\n",
       " 464: 2.3733239415104594,\n",
       " 465: 2.3725442003957475,\n",
       " 466: 2.3717649494752453,\n",
       " 467: 2.370986182783129,\n",
       " 468: 2.370207894515334,\n",
       " 469: 2.3694300790250993,\n",
       " 470: 2.3686527308186345,\n",
       " 471: 2.367875844550907,\n",
       " 472: 2.3670994150215456,\n",
       " 473: 2.3663234371708546,\n",
       " 474: 2.365547906075942,\n",
       " 475: 2.364772816946948,\n",
       " 476: 2.3639981651233843,\n",
       " 477: 2.3632239460705686,\n",
       " 478: 2.3624501553761594,\n",
       " 479: 2.3616767887467867,\n",
       " 480: 2.3609038420047765,\n",
       " 481: 2.3601313110849613,\n",
       " 482: 2.3593591920315826,\n",
       " 483: 2.3585874809952765,\n",
       " 484: 2.357816174230144,\n",
       " 485: 2.3570452680909,\n",
       " 486: 2.3562747590301028,\n",
       " 487: 2.3555046435954576,\n",
       " 488: 2.3547349184271975,\n",
       " 489: 2.3539655802555313,\n",
       " 490: 2.35319662589817,\n",
       " 491: 2.352428052257912,\n",
       " 492: 2.3516598563203006,\n",
       " 493: 2.350892035151346,\n",
       " 494: 2.350124585895307,\n",
       " 495: 2.349357505772537,\n",
       " 496: 2.348590792077386,\n",
       " 497: 2.3478244421761643,\n",
       " 498: 2.347058453505158,\n",
       " 499: 2.346292823568705,\n",
       " 500: 2.345527549937315,\n",
       " 501: 2.3447626302458526,\n",
       " 502: 2.34399806219176,\n",
       " 503: 2.3432338435333375,\n",
       " 504: 2.3424699720880606,\n",
       " 505: 2.3417064457309578,\n",
       " 506: 2.34094326239302,\n",
       " 507: 2.34018042005966,\n",
       " 508: 2.339417916769216,\n",
       " 509: 2.338655750611489,\n",
       " 510: 2.3378939197263313,\n",
       " 511: 2.337132422302261,\n",
       " 512: 2.3363712565751285,\n",
       " 513: 2.335610420826807,\n",
       " 514: 2.3348499133839304,\n",
       " 515: 2.3340897326166536,\n",
       " 516: 2.3333298769374604,\n",
       " 517: 2.3325703447999935,\n",
       " 518: 2.3318111346979236,\n",
       " 519: 2.331052245163845,\n",
       " 520: 2.330293674768204,\n",
       " 521: 2.3295354221182585,\n",
       " 522: 2.3287774858570605,\n",
       " 523: 2.3280198646624735,\n",
       " 524: 2.327262557246212,\n",
       " 525: 2.326505562352911,\n",
       " 526: 2.3257488787592173,\n",
       " 527: 2.32499250527291,\n",
       " 528: 2.3242364407320424,\n",
       " 529: 2.3234806840041085,\n",
       " 530: 2.3227252339852313,\n",
       " 531: 2.321970089599377,\n",
       " 532: 2.321215249797586,\n",
       " 533: 2.320460713557228,\n",
       " 534: 2.3197064798812774,\n",
       " 535: 2.318952547797611,\n",
       " 536: 2.3181989163583157,\n",
       " 537: 2.3174455846390294,\n",
       " 538: 2.3166925517382886,\n",
       " 539: 2.3159398167768983,\n",
       " 540: 2.31518737889732,\n",
       " 541: 2.3144352372630763,\n",
       " 542: 2.3136833910581687,\n",
       " 543: 2.312931839486517,\n",
       " 544: 2.3121805817714085,\n",
       " 545: 2.3114296171549658,\n",
       " 546: 2.3106789448976297,\n",
       " 547: 2.309928564277655,\n",
       " 548: 2.309178474590616,\n",
       " 549: 2.308428675148938,\n",
       " 550: 2.3076791652814257,\n",
       " 551: 2.306929944332817,\n",
       " 552: 2.306181011663345,\n",
       " 553: 2.305432366648307,\n",
       " 554: 2.3046840086776568,\n",
       " 555: 2.3039359371555967,\n",
       " 556: 2.303188151500187,\n",
       " 557: 2.302440651142966,\n",
       " 558: 2.301693435528577,\n",
       " 559: 2.3009465041144095,\n",
       " 560: 2.300199856370249,\n",
       " 561: 2.2994534917779355,\n",
       " 562: 2.298707409831031,\n",
       " 563: 2.2979616100345006,\n",
       " 564: 2.297216091904395,\n",
       " 565: 2.296470854967547,\n",
       " 566: 2.295725898761279,\n",
       " 567: 2.2949812228331083,\n",
       " 568: 2.294236826740471,\n",
       " 569: 2.293492710050449,\n",
       " 570: 2.2927488723395038,\n",
       " 571: 2.2920053131932208,\n",
       " 572: 2.2912620322060553,\n",
       " 573: 2.2905190289810933,\n",
       " 574: 2.2897763031298104,\n",
       " 575: 2.2890338542718442,\n",
       " 576: 2.2882916820347687,\n",
       " 577: 2.287549786053876,\n",
       " 578: 2.2868081659719657,\n",
       " 579: 2.2860668214391393,\n",
       " 580: 2.285325752112597,\n",
       " 581: 2.2845849576564463,\n",
       " 582: 2.28384443774151,\n",
       " 583: 2.2831041920451427,\n",
       " 584: 2.2823642202510515,\n",
       " 585: 2.2816245220491225,\n",
       " 586: 2.2808850971352514,\n",
       " 587: 2.280145945211176,\n",
       " 588: 2.2794070659843206,\n",
       " 589: 2.278668459167636,\n",
       " 590: 2.27793012447945,\n",
       " 591: 2.2771920616433197,\n",
       " 592: 2.276454270387889,\n",
       " 593: 2.275716750446747,\n",
       " 594: 2.2749795015582954,\n",
       " 595: 2.274242523465615,\n",
       " 596: 2.2735058159163373,\n",
       " 597: 2.2727693786625207,\n",
       " 598: 2.27203321146053,\n",
       " 599: 2.271297314070916,\n",
       " 600: 2.270561686258305,\n",
       " 601: 2.269826327791284,\n",
       " 602: 2.269091238442292,\n",
       " 603: 2.2683564179875186,\n",
       " 604: 2.267621866206797,\n",
       " 605: 2.2668875828835082,\n",
       " 606: 2.2661535678044804,\n",
       " 607: 2.2654198207598975,\n",
       " 608: 2.264686341543208,\n",
       " 609: 2.2639531299510325,\n",
       " 610: 2.2632201857830805,\n",
       " 611: 2.2624875088420637,\n",
       " 612: 2.261755098933617,\n",
       " 613: 2.2610229558662156,\n",
       " 614: 2.2602910794510986,\n",
       " 615: 2.259559469502195,\n",
       " 616: 2.2588281258360516,\n",
       " 617: 2.2580970482717544,\n",
       " 618: 2.2573662366308693,\n",
       " 619: 2.256635690737368,\n",
       " 620: 2.2559054104175646,\n",
       " 621: 2.2551753955000526,\n",
       " 622: 2.2544456458156414,\n",
       " 623: 2.253716161197297,\n",
       " 624: 2.2529869414800836,\n",
       " 625: 2.252257986501106,\n",
       " 626: 2.2515292960994544,\n",
       " 627: 2.250800870116151,\n",
       " 628: 2.2500727083940975,\n",
       " 629: 2.2493448107780236,\n",
       " 630: 2.2486171771144368,\n",
       " 631: 2.2478898072515765,\n",
       " 632: 2.247162701039367,\n",
       " 633: 2.246435858329368,\n",
       " 634: 2.2457092789747355,\n",
       " 635: 2.2449829628301754,\n",
       " 636: 2.2442569097519023,\n",
       " 637: 2.243531119597599,\n",
       " 638: 2.2428055922263788,\n",
       " 639: 2.242080327498743,\n",
       " 640: 2.2413553252765466,\n",
       " 641: 2.2406305854229602,\n",
       " 642: 2.239906107802437,\n",
       " 643: 2.2391818922806745,\n",
       " 644: 2.2384579387245838,\n",
       " 645: 2.237734247002256,\n",
       " 646: 2.2370108169829335,\n",
       " 647: 2.2362876485369725,\n",
       " 648: 2.2355647415358195,\n",
       " 649: 2.2348420958519806,\n",
       " 650: 2.234119711358989,\n",
       " 651: 2.2333975879313845,\n",
       " 652: 2.2326757254446816,\n",
       " 653: 2.2319541237753446,\n",
       " 654: 2.2312327828007628,\n",
       " 655: 2.2305117023992267,\n",
       " 656: 2.229790882449901,\n",
       " 657: 2.229070322832804,\n",
       " 658: 2.2283500234287863,\n",
       " 659: 2.2276299841195044,\n",
       " 660: 2.226910204787402,\n",
       " 661: 2.2261906853156885,\n",
       " 662: 2.2254714255883212,\n",
       " 663: 2.2247524254899806,\n",
       " 664: 2.224033684906057,\n",
       " 665: 2.223315203722626,\n",
       " 666: 2.222596981826436,\n",
       " 667: 2.2218790191048856,\n",
       " 668: 2.2211613154460106,\n",
       " 669: 2.220443870738465,\n",
       " 670: 2.219726684871504,\n",
       " 671: 2.2190097577349728,\n",
       " 672: 2.2182930892192854,\n",
       " 673: 2.2175766792154143,\n",
       " 674: 2.2168605276148714,\n",
       " 675: 2.2161446343096993,\n",
       " 676: 2.2154289991924534,\n",
       " 677: 2.214713622156192,\n",
       " 678: 2.2139985030944587,\n",
       " 679: 2.213283641901275,\n",
       " 680: 2.2125690384711247,\n",
       " 681: 2.2118546926989424,\n",
       " 682: 2.211140604480103,\n",
       " 683: 2.210426773710411,\n",
       " 684: 2.2097132002860858,\n",
       " 685: 2.208999884103756,\n",
       " 686: 2.208286825060445,\n",
       " 687: 2.2075740230535654,\n",
       " 688: 2.2068614779809024,\n",
       " 689: 2.2061491897406107,\n",
       " 690: 2.205437158231204,\n",
       " 691: 2.204725383351542,\n",
       " 692: 2.204013865000826,\n",
       " 693: 2.20330260307859,\n",
       " 694: 2.202591597484689,\n",
       " 695: 2.2018808481192935,\n",
       " 696: 2.2011703548828843,\n",
       " 697: 2.2004601176762373,\n",
       " 698: 2.1997501364004246,\n",
       " 699: 2.1990404109568025,\n",
       " 700: 2.198330941247004,\n",
       " 701: 2.1976217271729346,\n",
       " 702: 2.196912768636765,\n",
       " 703: 2.196204065540923,\n",
       " 704: 2.195495617788089,\n",
       " 705: 2.194787425281189,\n",
       " 706: 2.194079487923389,\n",
       " 707: 2.1933718056180895,\n",
       " 708: 2.19266437826892,\n",
       " 709: 2.1919572057797314,\n",
       " 710: 2.1912502880545945,\n",
       " 711: 2.1905436249977916,\n",
       " 712: 2.1898372165138134,\n",
       " 713: 2.1891310625073523,\n",
       " 714: 2.1884251628833,\n",
       " 715: 2.1877195175467405,\n",
       " 716: 2.1870141264029477,\n",
       " 717: 2.1863089893573804,\n",
       " 718: 2.1856041063156755,\n",
       " 719: 2.1848994771836487,\n",
       " 720: 2.1841951018672874,\n",
       " 721: 2.1834909802727465,\n",
       " 722: 2.1827871123063454,\n",
       " 723: 2.1820834978745656,\n",
       " 724: 2.1813801368840444,\n",
       " 725: 2.180677029241574,\n",
       " 726: 2.179974174854096,\n",
       " 727: 2.1792715736286996,\n",
       " 728: 2.1785692254726183,\n",
       " 729: 2.1778671302932255,\n",
       " 730: 2.1771652879980326,\n",
       " 731: 2.1764636984946857,\n",
       " 732: 2.1757623616909636,\n",
       " 733: 2.175061277494773,\n",
       " 734: 2.1743604458141474,\n",
       " 735: 2.1736598665572444,\n",
       " 736: 2.1729595396323425,\n",
       " 737: 2.172259464947839,\n",
       " 738: 2.171559642412247,\n",
       " 739: 2.1708600719341935,\n",
       " 740: 2.1701607534224183,\n",
       " 741: 2.169461686785769,\n",
       " 742: 2.168762871933201,\n",
       " 743: 2.1680643087737757,\n",
       " 744: 2.167365997216655,\n",
       " 745: 2.166667937171104,\n",
       " 746: 2.1659701285464874,\n",
       " 747: 2.165272571252265,\n",
       " 748: 2.1645752651979926,\n",
       " 749: 2.16387821029332,\n",
       " 750: 2.1631814064479884,\n",
       " 751: 2.1624848535718297,\n",
       " 752: 2.1617885515747646,\n",
       " 753: 2.1610925003667987,\n",
       " 754: 2.1603966998580244,\n",
       " 755: 2.1597011499586185,\n",
       " 756: 2.159005850578838,\n",
       " 757: 2.158310801629023,\n",
       " 758: 2.1576160030195917,\n",
       " 759: 2.156921454661041,\n",
       " 760: 2.1562271564639444,\n",
       " 761: 2.1555331083389513,\n",
       " 762: 2.1548393101967847,\n",
       " 763: 2.1541457619482416,\n",
       " 764: 2.1534524635041903,\n",
       " 765: 2.15275941477557,\n",
       " 766: 2.152066615673389,\n",
       " 767: 2.1513740661087257,\n",
       " 768: 2.150681765992724,\n",
       " 769: 2.1499897152365954,\n",
       " 770: 2.149297913751617,\n",
       " 771: 2.1486063614491298,\n",
       " 772: 2.1479150582405384,\n",
       " 773: 2.147224004037311,\n",
       " 774: 2.146533198750976,\n",
       " 775: 2.1458426422931236,\n",
       " 776: 2.145152334575404,\n",
       " 777: 2.1444622755095266,\n",
       " 778: 2.1437724650072596,\n",
       " 779: 2.1430829029804257,\n",
       " 780: 2.14239358934091,\n",
       " 781: 2.14170452400065,\n",
       " 782: 2.141015706871638,\n",
       " 783: 2.140327137865923,\n",
       " 784: 2.139638816895608,\n",
       " 785: 2.1389507438728477,\n",
       " 786: 2.1382629187098514,\n",
       " 787: 2.1375753413188794,\n",
       " 788: 2.1368880116122426,\n",
       " 789: 2.1362009295023054,\n",
       " 790: 2.13551409490148,\n",
       " 791: 2.13482750772223,\n",
       " 792: 2.134141167877067,\n",
       " 793: 2.133455075278552,\n",
       " 794: 2.132769229839294,\n",
       " 795: 2.1320836314719496,\n",
       " 796: 2.1313982800892224,\n",
       " 797: 2.1307131756038635,\n",
       " 798: 2.13002831792867,\n",
       " 799: 2.1293437069764827,\n",
       " 800: 2.1286593426601907,\n",
       " 801: 2.1279752248927273,\n",
       " 802: 2.127291353587069,\n",
       " 803: 2.126607728656237,\n",
       " 804: 2.1259243500132974,\n",
       " 805: 2.1252412175713573,\n",
       " 806: 2.124558331243569,\n",
       " 807: 2.1238756909431262,\n",
       " 808: 2.123193296583265,\n",
       " 809: 2.122511148077264,\n",
       " 810: 2.121829245338442,\n",
       " 811: 2.1211475882801607,\n",
       " 812: 2.1204661768158215,\n",
       " 813: 2.1197850108588665,\n",
       " 814: 2.1191040903227796,\n",
       " 815: 2.1184234151210823,\n",
       " 816: 2.1177429851673377,\n",
       " 817: 2.117062800375148,\n",
       " 818: 2.1163828606581534,\n",
       " 819: 2.115703165930035,\n",
       " 820: 2.115023716104511,\n",
       " 821: 2.114344511095338,\n",
       " 822: 2.1136655508163127,\n",
       " 823: 2.112986835181267,\n",
       " 824: 2.112308364104073,\n",
       " 825: 2.1116301374986386,\n",
       " 826: 2.11095215527891,\n",
       " 827: 2.1102744173588692,\n",
       " 828: 2.1095969236525365,\n",
       " 829: 2.1089196740739684,\n",
       " 830: 2.1082426685372577,\n",
       " 831: 2.107565906956533,\n",
       " 832: 2.10688938924596,\n",
       " 833: 2.1062131153197394,\n",
       " 834: 2.105537085092108,\n",
       " 835: 2.104861298477339,\n",
       " 836: 2.1041857553897385,\n",
       " 837: 2.1035104557436513,\n",
       " 838: 2.102835399453454,\n",
       " 839: 2.102160586433561,\n",
       " 840: 2.101486016598419,\n",
       " 841: 2.1008116898625104,\n",
       " 842: 2.1001376061403527,\n",
       " 843: 2.099463765346496,\n",
       " 844: 2.0987901673955265,\n",
       " 845: 2.098116812202064,\n",
       " 846: 2.097443699680761,\n",
       " 847: 2.0967708297463052,\n",
       " 848: 2.096098202313417,\n",
       " 849: 2.0954258172968516,\n",
       " 850: 2.0947536746113964,\n",
       " 851: 2.0940817741718725,\n",
       " 852: 2.093410115893135,\n",
       " 853: 2.092738699690071,\n",
       " 854: 2.0920675254776016,\n",
       " 855: 2.09139659317068,\n",
       " 856: 2.0907259026842926,\n",
       " 857: 2.090055453933458,\n",
       " 858: 2.0893852468332295,\n",
       " 859: 2.088715281298689,\n",
       " 860: 2.088045557244955,\n",
       " 861: 2.0873760745871768,\n",
       " 862: 2.086706833240534,\n",
       " 863: 2.086037833120241,\n",
       " 864: 2.0853690741415445,\n",
       " 865: 2.0847005562197194,\n",
       " 866: 2.0840322792700783,\n",
       " 867: 2.0833642432079604,\n",
       " 868: 2.08269644794874,\n",
       " 869: 2.0820288934078213,\n",
       " 870: 2.0813615795006415,\n",
       " 871: 2.0806945061426685,\n",
       " 872: 2.080027673249402,\n",
       " 873: 2.0793610807363727,\n",
       " 874: 2.078694728519144,\n",
       " 875: 2.0780286165133086,\n",
       " 876: 2.0773627446344918,\n",
       " 877: 2.07669711279835,\n",
       " 878: 2.0760317209205716,\n",
       " 879: 2.0753665689168734,\n",
       " 880: 2.0747016567030054,\n",
       " 881: 2.074036984194749,\n",
       " 882: 2.0733725513079135,\n",
       " 883: 2.072708357958343,\n",
       " 884: 2.0720444040619097,\n",
       " 885: 2.0713806895345175,\n",
       " 886: 2.0707172142921006,\n",
       " 887: 2.070053978250625,\n",
       " 888: 2.0693909813260856,\n",
       " 889: 2.068728223434509,\n",
       " 890: 2.0680657044919513,\n",
       " 891: 2.067403424414501,\n",
       " 892: 2.066741383118275,\n",
       " 893: 2.0660795805194216,\n",
       " 894: 2.0654180165341205,\n",
       " 895: 2.0647566910785784,\n",
       " 896: 2.0640956040690357,\n",
       " 897: 2.063434755421761,\n",
       " 898: 2.0627741450530546,\n",
       " 899: 2.0621137728792456,\n",
       " 900: 2.061453638816694,\n",
       " 901: 2.0607937427817893,\n",
       " 902: 2.0601340846909517,\n",
       " 903: 2.0594746644606308,\n",
       " 904: 2.0588154820073066,\n",
       " 905: 2.0581565372474895,\n",
       " 906: 2.0574978300977182,\n",
       " 907: 2.056839360474563,\n",
       " 908: 2.056181128294623,\n",
       " 909: 2.0555231334745274,\n",
       " 910: 2.0548653759309357,\n",
       " 911: 2.054207855580537,\n",
       " 912: 2.053550572340049,\n",
       " 913: 2.0528935261262204,\n",
       " 914: 2.052236716855829,\n",
       " 915: 2.0515801444456825,\n",
       " 916: 2.0509238088126183,\n",
       " 917: 2.0502677098735025,\n",
       " 918: 2.0496118475452314,\n",
       " 919: 2.0489562217447315,\n",
       " 920: 2.0483008323889584,\n",
       " 921: 2.0476456793948965,\n",
       " 922: 2.0469907626795605,\n",
       " 923: 2.046336082159993,\n",
       " 924: 2.0456816377532685,\n",
       " 925: 2.045027429376489,\n",
       " 926: 2.044373456946787,\n",
       " 927: 2.0437197203813233,\n",
       " 928: 2.0430662195972884,\n",
       " 929: 2.042412954511902,\n",
       " 930: 2.0417599250424145,\n",
       " 931: 2.0411071311061035,\n",
       " 932: 2.040454572620277,\n",
       " 933: 2.0398022495022707,\n",
       " 934: 2.0391501616694523,\n",
       " 935: 2.038498309039216,\n",
       " 936: 2.0378466915289875,\n",
       " 937: 2.0371953090562194,\n",
       " 938: 2.036544161538394,\n",
       " 939: 2.0358932488930233,\n",
       " 940: 2.035242571037649,\n",
       " 941: 2.0345921278898405,\n",
       " 942: 2.0339419193671966,\n",
       " 943: 2.0332919453873455,\n",
       " 944: 2.032642205867944,\n",
       " 945: 2.031992700726678,\n",
       " 946: 2.0313434298812623,\n",
       " 947: 2.0306943932494415,\n",
       " 948: 2.0300455907489874,\n",
       " 949: 2.029397022297703,\n",
       " 950: 2.0287486878134176,\n",
       " 951: 2.028100587213992,\n",
       " 952: 2.027452720417313,\n",
       " 953: 2.0268050873412995,\n",
       " 954: 2.026157687903896,\n",
       " 955: 2.0255105220230787,\n",
       " 956: 2.0248635896168494,\n",
       " 957: 2.0242168906032436,\n",
       " 958: 2.02357042490032,\n",
       " 959: 2.02292419242617,\n",
       " 960: 2.022278193098911,\n",
       " 961: 2.021632426836691,\n",
       " 962: 2.020986893557687,\n",
       " 963: 2.0203415931801025,\n",
       " 964: 2.0196965256221717,\n",
       " 965: 2.0190516908021574,\n",
       " 966: 2.0184070886383494,\n",
       " 967: 2.0177627190490686,\n",
       " 968: 2.0171185819526607,\n",
       " 969: 2.016474677267505,\n",
       " 970: 2.0158310049120045,\n",
       " 971: 2.015187564804595,\n",
       " 972: 2.0145443568637385,\n",
       " 973: 2.0139013810079254,\n",
       " 974: 2.0132586371556753,\n",
       " 975: 2.012616125225537,\n",
       " 976: 2.011973845136086,\n",
       " 977: 2.011331796805929,\n",
       " 978: 2.010689980153698,\n",
       " 979: 2.010048395098055,\n",
       " 980: 2.0094070415576923,\n",
       " 981: 2.008765919451327,\n",
       " 982: 2.008125028697707,\n",
       " 983: 2.0074843692156086,\n",
       " 984: 2.0068439409238357,\n",
       " 985: 2.0062037437412203,\n",
       " 986: 2.005563777586625,\n",
       " 987: 2.0049240423789367,\n",
       " 988: 2.0042845380370755,\n",
       " 989: 2.003645264479986,\n",
       " 990: 2.0030062216266433,\n",
       " 991: 2.002367409396049,\n",
       " 992: 2.0017288277072356,\n",
       " 993: 2.0010904764792605,\n",
       " 994: 2.0004523556312144,\n",
       " 995: 1.99981446508221,\n",
       " 996: 1.9991768047513927,\n",
       " 997: 1.9985393745579352,\n",
       " 998: 1.9979021744210372,\n",
       " 999: 1.9972652042599284,\n",
       " 1000: 1.9966284639938654,\n",
       " ...}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Your code is here\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d285c55",
   "metadata": {},
   "source": [
    "В машинном обучении зачастую исследуют так называемые **траектории обучения** (или **learning paths**). Это графики, показывающие, как во время обучения при каждой следующей итерации изменялось значение минимизируемого функционала. Постройте такие траектории для различных **learning rate**'ов и **threshold**'ов. Советуем использовать для этого разобранный на занятиях **add_subplot** метод. \n",
    "\n",
    "Возьмите следующие **threshold**'ы: 1e-2, 1e-3, 1e-4, 1e-5\n",
    "\n",
    "И следующие значения **learning rate**'а: 1e-1, 5e-2, 1e-2, 5e-3, 1e-3\n",
    "\n",
    "У вас должен получиться примерно такой график (см. ниже, значения среднеквадратической ошибки мы намеренно замазали оранжевыми квадратиками, чтобы не спойлерить вам результаты).\n",
    "\n",
    "Как и подобает хорошим Data Scientist'ам, не забывайте подписывать графики, оси, а так же делать элементы ваших визуализаций читаемыми и видимыми. Советуем пересмотреть методы и параметры форматирования из лекции.\n",
    "\n",
    "При какой комбинации **threshold** - **learning rate** из возможных предложенных выше, получается достигнуть меньшего значения нашей минимизируемой функции? Запишите каждой из значений в легенде на графиках.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3890b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Your code is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570d75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed146b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
